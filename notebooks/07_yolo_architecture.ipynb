{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üèóÔ∏è Task 7: YOLO Architecture Deep Dive\n",
                "\n",
                "## üéØ Objective\n",
                "Understand the complete YOLOv11 architecture - from input image to detection output.\n",
                "\n",
                "---\n",
                "\n",
                "## üìö YOLO Evolution\n",
                "\n",
                "| Version | Year | Key Innovation |\n",
                "|---------|------|----------------|\n",
                "| YOLOv1 | 2016 | Single-shot detection |\n",
                "| YOLOv3 | 2018 | Multi-scale predictions |\n",
                "| YOLOv5 | 2020 | PyTorch, easy training |\n",
                "| YOLOv8 | 2023 | Anchor-free, decoupled head |\n",
                "| **YOLOv11** | 2024 | C2PSA, improved efficiency |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "PROJECT_ROOT = Path(r\"D:\\het\\SELF\\RP\\YOLO-V11-PRO\")\n",
                "print(\"‚úÖ Libraries imported!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: YOLO High-Level Architecture\n",
                "\n",
                "## üèóÔ∏è Three Main Components\n",
                "\n",
                "```\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ                        YOLOv11                              ‚îÇ\n",
                "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "‚îÇ    BACKBONE    ‚îÇ      NECK      ‚îÇ          HEAD             ‚îÇ\n",
                "‚îÇ   (CSPDarknet) ‚îÇ  (PANet+FPN)   ‚îÇ   (Decoupled Head)        ‚îÇ\n",
                "‚îÇ                ‚îÇ                ‚îÇ                           ‚îÇ\n",
                "‚îÇ  Feature       ‚îÇ  Feature       ‚îÇ  Classification +         ‚îÇ\n",
                "‚îÇ  Extraction    ‚îÇ  Fusion        ‚îÇ  Box Regression           ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "        ‚Üì                ‚Üì                      ‚Üì\n",
                "   Low‚ÜíHigh          Multi-scale         Final Predictions\n",
                "   Features          Features            [class, x, y, w, h]\n",
                "```\n",
                "\n",
                "### 1. Backbone: Feature Extraction\n",
                "- Extracts hierarchical features from input image\n",
                "- Uses CSPDarknet (Cross Stage Partial)\n",
                "- Output: Feature maps at different scales\n",
                "\n",
                "### 2. Neck: Feature Fusion\n",
                "- Combines features from different scales\n",
                "- PANet (Path Aggregation Network) + FPN (Feature Pyramid)\n",
                "- Enables detecting objects of various sizes\n",
                "\n",
                "### 3. Head: Detection\n",
                "- Decoupled head (separate cls/reg branches)\n",
                "- Anchor-free design\n",
                "- Outputs: Class probabilities + Bounding box coordinates"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: Backbone - CSPDarknet\n",
                "\n",
                "## üìê Key Concepts\n",
                "\n",
                "### Cross Stage Partial (CSP) Network\n",
                "Splits feature map into two parts:\n",
                "- One part goes through dense layers\n",
                "- Other part skips directly\n",
                "- Both merged at the end\n",
                "\n",
                "**Benefits:**\n",
                "- Reduces computation\n",
                "- Reduces memory usage\n",
                "- Maintains accuracy\n",
                "\n",
                "```\n",
                "Input Feature Map\n",
                "       ‚îÇ\n",
                "   ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê\n",
                "   ‚îÇ Split ‚îÇ\n",
                "   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò\n",
                "   ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê\n",
                "   ‚Üì       ‚Üì\n",
                "Part 1   Part 2\n",
                "   ‚îÇ       ‚îÇ\n",
                "Dense    Skip\n",
                "Layers   Connection\n",
                "   ‚îÇ       ‚îÇ\n",
                "   ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò\n",
                "       ‚îÇ\n",
                "   Concatenate\n",
                "       ‚îÇ\n",
                "   Output\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# VISUALIZE BACKBONE FEATURE EXTRACTION\n",
                "# ============================================================\n",
                "\n",
                "def visualize_backbone_concept():\n",
                "    \"\"\"Visualize how backbone extracts multi-scale features.\"\"\"\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 5, figsize=(16, 4))\n",
                "    fig.suptitle('üîç Backbone: Multi-Scale Feature Extraction', fontsize=14, fontweight='bold')\n",
                "    \n",
                "    # Simulate feature map sizes at different stages\n",
                "    stages = [\n",
                "        ('Input\\n640√ó640√ó3', 640, 'lightblue'),\n",
                "        ('Stage 1\\n320√ó320√ó64', 320, 'lightgreen'),\n",
                "        ('Stage 2\\n160√ó160√ó128', 160, 'yellow'),\n",
                "        ('Stage 3\\n80√ó80√ó256', 80, 'orange'),\n",
                "        ('Stage 4\\n40√ó40√ó512', 40, 'red'),\n",
                "    ]\n",
                "    \n",
                "    for ax, (label, size, color) in zip(axes, stages):\n",
                "        # Draw rectangle representing feature map\n",
                "        rect = plt.Rectangle((0.1, 0.1), 0.8, 0.8, fill=True, color=color, alpha=0.6)\n",
                "        ax.add_patch(rect)\n",
                "        ax.text(0.5, 0.5, label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
                "        ax.set_xlim(0, 1)\n",
                "        ax.set_ylim(0, 1)\n",
                "        ax.set_aspect('equal')\n",
                "        ax.axis('off')\n",
                "    \n",
                "    # Draw arrows\n",
                "    for i in range(4):\n",
                "        plt.annotate('', xy=(0.22 + i*0.2, 0.5), xytext=(0.18 + i*0.2, 0.5),\n",
                "                    xycoords='figure fraction',\n",
                "                    arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'backbone_stages.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_backbone_concept()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 3: Neck - Feature Pyramid + PANet\n",
                "\n",
                "## üìê Feature Pyramid Network (FPN)\n",
                "\n",
                "Combines features from different scales:\n",
                "\n",
                "```\n",
                "Backbone Output:          FPN:\n",
                "                    \n",
                "P5 (40√ó40)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  P5 ‚îÄ‚îÄ‚îÄ‚îê\n",
                "                              ‚Üì upsample\n",
                "P4 (80√ó80)  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  P4 ‚îÄ‚îÄ‚îÄ‚î§ + lateral\n",
                "                              ‚Üì upsample  \n",
                "P3 (160√ó160) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  P3 ‚îÄ‚îÄ‚îÄ‚î§ + lateral\n",
                "```\n",
                "\n",
                "## Path Aggregation Network (PANet)\n",
                "\n",
                "Adds bottom-up path after FPN:\n",
                "\n",
                "```\n",
                "FPN Output:           PANet:\n",
                "\n",
                "P3 (large) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ N3 ‚îÄ‚îÄ‚îÄ‚îê\n",
                "                             ‚Üì downsample\n",
                "P4 (medium) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ N4 ‚îÄ‚îÄ‚îÄ‚î§ + lateral\n",
                "                             ‚Üì downsample\n",
                "P5 (small) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ N5 ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```\n",
                "\n",
                "**Why both directions?**\n",
                "- Top-down (FPN): Semantic information flows down\n",
                "- Bottom-up (PANet): Localization information flows up"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize FPN + PANet\n",
                "def visualize_neck():\n",
                "    \"\"\"Visualize the Neck architecture (FPN + PANet).\"\"\"\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(12, 8))\n",
                "    ax.set_xlim(0, 12)\n",
                "    ax.set_ylim(0, 10)\n",
                "    \n",
                "    # Backbone outputs\n",
                "    backbone_boxes = [\n",
                "        (1, 7, 1.5, 1.5, 'P5\\n40√ó40', 'lightcoral'),\n",
                "        (1, 4.5, 2, 2, 'P4\\n80√ó80', 'lightyellow'),\n",
                "        (1, 1.5, 2.5, 2.5, 'P3\\n160√ó160', 'lightgreen'),\n",
                "    ]\n",
                "    \n",
                "    # FPN outputs\n",
                "    fpn_boxes = [\n",
                "        (5, 7, 1.5, 1.5, 'F5', 'coral'),\n",
                "        (5, 4.5, 2, 2, 'F4', 'yellow'),\n",
                "        (5, 1.5, 2.5, 2.5, 'F3', 'green'),\n",
                "    ]\n",
                "    \n",
                "    # PANet outputs\n",
                "    panet_boxes = [\n",
                "        (9, 7, 1.5, 1.5, 'N5', 'darkred'),\n",
                "        (9, 4.5, 2, 2, 'N4', 'goldenrod'),\n",
                "        (9, 1.5, 2.5, 2.5, 'N3', 'darkgreen'),\n",
                "    ]\n",
                "    \n",
                "    # Draw boxes\n",
                "    for boxes, label in [(backbone_boxes, 'Backbone'), (fpn_boxes, 'FPN'), (panet_boxes, 'PANet')]:\n",
                "        for x, y, w, h, text, color in boxes:\n",
                "            rect = plt.Rectangle((x, y), w, h, fill=True, color=color, alpha=0.7, edgecolor='black')\n",
                "            ax.add_patch(rect)\n",
                "            ax.text(x + w/2, y + h/2, text, ha='center', va='center', fontsize=10, fontweight='bold')\n",
                "    \n",
                "    # Labels\n",
                "    ax.text(2, 9.5, 'Backbone', ha='center', fontsize=12, fontweight='bold')\n",
                "    ax.text(6, 9.5, 'FPN (Top-Down)', ha='center', fontsize=12, fontweight='bold')\n",
                "    ax.text(10, 9.5, 'PANet (Bottom-Up)', ha='center', fontsize=12, fontweight='bold')\n",
                "    \n",
                "    # Arrows\n",
                "    # Backbone to FPN\n",
                "    for y in [7.75, 5.5, 2.75]:\n",
                "        ax.annotate('', xy=(4.9, y), xytext=(3.6, y),\n",
                "                   arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
                "    \n",
                "    # FPN vertical (top-down)\n",
                "    ax.annotate('', xy=(6, 6.4), xytext=(6, 6.9), arrowprops=dict(arrowstyle='->', color='blue', lw=2))\n",
                "    ax.annotate('', xy=(6, 3.9), xytext=(6, 4.4), arrowprops=dict(arrowstyle='->', color='blue', lw=2))\n",
                "    \n",
                "    # FPN to PANet\n",
                "    for y in [7.75, 5.5, 2.75]:\n",
                "        ax.annotate('', xy=(8.9, y), xytext=(7.1, y),\n",
                "                   arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
                "    \n",
                "    # PANet vertical (bottom-up)\n",
                "    ax.annotate('', xy=(10, 4.4), xytext=(10, 4.1), arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
                "    ax.annotate('', xy=(10, 6.9), xytext=(10, 6.6), arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
                "    \n",
                "    ax.set_title('üîÑ Neck: FPN + PANet Feature Fusion', fontsize=14, fontweight='bold')\n",
                "    ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'neck_architecture.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_neck()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 4: Head - Decoupled Detection Head\n",
                "\n",
                "## üìê Anchor-Free Design\n",
                "\n",
                "YOLOv11 uses **anchor-free** detection:\n",
                "- No predefined anchor boxes\n",
                "- Directly predicts box coordinates\n",
                "- Simpler, faster training\n",
                "\n",
                "## Decoupled Head\n",
                "\n",
                "Separates classification and regression:\n",
                "\n",
                "```\n",
                "Feature Map\n",
                "     ‚îÇ\n",
                "     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "     ‚îÇ              ‚îÇ              ‚îÇ\n",
                "     ‚Üì              ‚Üì              ‚Üì\n",
                "Classification   Box Reg        DFL\n",
                "  Branch        Branch       (Distribution)\n",
                "     ‚îÇ              ‚îÇ              ‚îÇ\n",
                "     ‚Üì              ‚Üì              ‚Üì\n",
                "  Classes        x,y,w,h      Fine Bbox\n",
                "```\n",
                "\n",
                "## Output Format\n",
                "\n",
                "For each grid cell, output:\n",
                "- **Class scores**: [num_classes] probabilities\n",
                "- **Box coordinates**: [x, y, w, h] (center format)\n",
                "- **Objectness**: Confidence score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# YOLO OUTPUT VISUALIZATION\n",
                "# ============================================================\n",
                "\n",
                "def visualize_yolo_grid():\n",
                "    \"\"\"Visualize how YOLO divides image into grid.\"\"\"\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "    fig.suptitle('üéØ YOLO Detection at Multiple Scales', fontsize=14, fontweight='bold')\n",
                "    \n",
                "    scales = [\n",
                "        ('Large Objects\\n80√ó80 grid', 8),\n",
                "        ('Medium Objects\\n40√ó40 grid', 16),\n",
                "        ('Small Objects\\n20√ó20 grid', 32),\n",
                "    ]\n",
                "    \n",
                "    for ax, (title, grid_size) in zip(axes, scales):\n",
                "        # Draw grid\n",
                "        ax.set_xlim(0, 640)\n",
                "        ax.set_ylim(640, 0)\n",
                "        \n",
                "        # Draw grid lines\n",
                "        for i in range(0, 641, grid_size):\n",
                "            ax.axhline(y=i, color='blue', alpha=0.3, linewidth=0.5)\n",
                "            ax.axvline(x=i, color='blue', alpha=0.3, linewidth=0.5)\n",
                "        \n",
                "        # Highlight some cells\n",
                "        np.random.seed(42)\n",
                "        for _ in range(5):\n",
                "            x = np.random.randint(0, 640 // grid_size) * grid_size\n",
                "            y = np.random.randint(0, 640 // grid_size) * grid_size\n",
                "            rect = plt.Rectangle((x, y), grid_size, grid_size, fill=True, \n",
                "                                 color='green', alpha=0.5)\n",
                "            ax.add_patch(rect)\n",
                "        \n",
                "        ax.set_title(title)\n",
                "        ax.set_xlabel('640 pixels')\n",
                "        ax.set_aspect('equal')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'yolo_grid.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_yolo_grid()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 5: YOLOv11 Specific Features\n",
                "\n",
                "## C2PSA (Cross Stage Partial with Spatial Attention)\n",
                "\n",
                "New in YOLOv11:\n",
                "- Combines CSP with spatial attention\n",
                "- Better feature representation\n",
                "- Improved small object detection\n",
                "\n",
                "## Model Variants\n",
                "\n",
                "| Model | Params | mAP | Speed |\n",
                "|-------|--------|-----|-------|\n",
                "| yolo11n | 2.6M | 39.5 | Fast |\n",
                "| yolo11s | 9.4M | 47.0 | Fast |\n",
                "| yolo11m | 20.1M | 51.5 | Medium |\n",
                "| yolo11l | 25.3M | 53.4 | Slow |\n",
                "| yolo11x | 56.9M | 54.7 | Slowest |\n",
                "\n",
                "For this project, we'll use **yolo11n** (nano) for faster training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model comparison visualization\n",
                "def visualize_model_comparison():\n",
                "    \"\"\"Compare YOLOv11 model variants.\"\"\"\n",
                "    \n",
                "    models = ['yolo11n', 'yolo11s', 'yolo11m', 'yolo11l', 'yolo11x']\n",
                "    params = [2.6, 9.4, 20.1, 25.3, 56.9]  # Millions\n",
                "    mAP = [39.5, 47.0, 51.5, 53.4, 54.7]\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    \n",
                "    # Parameters\n",
                "    colors = plt.cm.viridis(np.linspace(0, 1, len(models)))\n",
                "    axes[0].bar(models, params, color=colors)\n",
                "    axes[0].set_ylabel('Parameters (M)')\n",
                "    axes[0].set_title('Model Size')\n",
                "    \n",
                "    # mAP\n",
                "    axes[1].bar(models, mAP, color=colors)\n",
                "    axes[1].set_ylabel('mAP@50')\n",
                "    axes[1].set_title('Performance')\n",
                "    \n",
                "    plt.suptitle('üìä YOLOv11 Model Variants', fontsize=14, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'model_comparison.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_model_comparison()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Summary\n",
                "\n",
                "### YOLOv11 Architecture:\n",
                "\n",
                "| Component | Purpose | Key Feature |\n",
                "|-----------|---------|-------------|\n",
                "| **Backbone** | Feature extraction | CSPDarknet + C2PSA |\n",
                "| **Neck** | Feature fusion | FPN + PANet |\n",
                "| **Head** | Detection | Decoupled, Anchor-free |\n",
                "\n",
                "### Key Concepts:\n",
                "1. Multi-scale detection (small, medium, large objects)\n",
                "2. Feature pyramid for semantic + localization info\n",
                "3. Anchor-free for simplified training\n",
                "4. Decoupled head for better convergence\n",
                "\n",
                "### Next: Task 8 - Loss Function Mathematics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TASK 7 COMPLETE: YOLO Architecture Deep Dive\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüìã Topics covered:\")\n",
                "print(\"   ‚úì YOLO evolution (v1 to v11)\")\n",
                "print(\"   ‚úì Backbone: CSPDarknet + C2PSA\")\n",
                "print(\"   ‚úì Neck: FPN + PANet\")\n",
                "print(\"   ‚úì Head: Decoupled, Anchor-free\")\n",
                "print(\"   ‚úì Multi-scale detection\")\n",
                "print(\"   ‚úì Model variants comparison\")\n",
                "print(\"\\n‚û°Ô∏è Ready for Task 8: Loss Functions\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}