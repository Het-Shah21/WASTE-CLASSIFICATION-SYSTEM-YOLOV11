{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Task 9: Setup YOLOv11 with Ultralytics\n",
                "\n",
                "## üéØ Objective\n",
                "Set up YOLOv11 using the Ultralytics library and prepare for training on our waste classification dataset.\n",
                "\n",
                "---\n",
                "\n",
                "## üìö About Ultralytics\n",
                "\n",
                "Ultralytics provides:\n",
                "- Easy YOLO model loading and training\n",
                "- Pre-trained weights for transfer learning\n",
                "- Built-in data augmentation\n",
                "- Training callbacks and logging\n",
                "\n",
                "### ML Rules Applied:\n",
                "- **Rule #4**: Keep the first model simple\n",
                "- **Rule #14**: Starting with an interpretable model\n",
                "- **Rule #38**: Test the model on new data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install ultralytics if not already installed\n",
                "# !pip install ultralytics\n",
                "\n",
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import yaml\n",
                "\n",
                "# Ultralytics\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# Project paths\n",
                "PROJECT_ROOT = Path(r\"D:\\het\\SELF\\RP\\YOLO-V11-PRO\")\n",
                "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
                "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
                "MODELS_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(\"‚úÖ Libraries imported!\")\n",
                "print(f\"üìÅ Project: {PROJECT_ROOT}\")\n",
                "print(f\"üìÅ Data: {DATA_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: Verify Dataset\n",
                "\n",
                "First, let's verify our dataset is ready for training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check dataset structure\n",
                "def verify_dataset():\n",
                "    \"\"\"Verify dataset is properly formatted for YOLO.\"\"\"\n",
                "    \n",
                "    dirs_to_check = [\n",
                "        DATA_DIR / \"images\" / \"train\",\n",
                "        DATA_DIR / \"images\" / \"val\",\n",
                "        DATA_DIR / \"labels\" / \"train\",\n",
                "        DATA_DIR / \"labels\" / \"val\",\n",
                "    ]\n",
                "    \n",
                "    print(\"üìÅ Dataset Structure Check:\")\n",
                "    print(\"=\"*50)\n",
                "    \n",
                "    all_ok = True\n",
                "    for d in dirs_to_check:\n",
                "        if d.exists():\n",
                "            count = len(list(d.glob(\"*\")))\n",
                "            print(f\"   ‚úÖ {d.name:15} : {count:5} files\")\n",
                "        else:\n",
                "            print(f\"   ‚ùå {d.name:15} : MISSING\")\n",
                "            all_ok = False\n",
                "    \n",
                "    # Check dataset.yaml\n",
                "    yaml_path = DATA_DIR / \"dataset.yaml\"\n",
                "    if yaml_path.exists():\n",
                "        print(f\"   ‚úÖ {'dataset.yaml':15} : EXISTS\")\n",
                "        with open(yaml_path, 'r') as f:\n",
                "            config = yaml.safe_load(f)\n",
                "            print(f\"\\nüìÑ Dataset Config:\")\n",
                "            print(f\"   Path: {config.get('path', 'N/A')}\")\n",
                "            print(f\"   Classes: {config.get('names', 'N/A')}\")\n",
                "    else:\n",
                "        print(f\"   ‚ùå {'dataset.yaml':15} : MISSING\")\n",
                "        all_ok = False\n",
                "    \n",
                "    return all_ok\n",
                "\n",
                "dataset_ready = verify_dataset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: Load YOLOv11 Model\n",
                "\n",
                "## Model Variants\n",
                "\n",
                "| Model | Size | mAP | Speed |\n",
                "|-------|------|-----|-------|\n",
                "| yolo11n | Nano | 39.5 | Fastest |\n",
                "| yolo11s | Small | 47.0 | Fast |\n",
                "| yolo11m | Medium | 51.5 | Moderate |\n",
                "| yolo11l | Large | 53.4 | Slow |\n",
                "| yolo11x | XLarge | 54.7 | Slowest |\n",
                "\n",
                "We'll use **yolo11n** (nano) for faster training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# LOAD YOLOV11 MODEL\n",
                "# ============================================================\n",
                "\n",
                "# Load pretrained model (nano for speed)\n",
                "model = YOLO('yolo11n.pt')  # Downloads automatically if not present\n",
                "\n",
                "print(\"\\n‚úÖ YOLOv11 Nano Model Loaded!\")\n",
                "print(f\"\\nüìä Model Info:\")\n",
                "print(f\"   Type: {type(model).__name__}\")\n",
                "print(f\"   Task: Detection\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model architecture summary\n",
                "print(\"\\nüìê Model Architecture Summary:\")\n",
                "print(\"=\"*50)\n",
                "model.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 3: Training Configuration\n",
                "\n",
                "Key hyperparameters for training:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# TRAINING CONFIGURATION\n",
                "# ============================================================\n",
                "\n",
                "train_config = {\n",
                "    # Dataset\n",
                "    'data': str(DATA_DIR / 'dataset.yaml'),\n",
                "    \n",
                "    # Training parameters\n",
                "    'epochs': 50,           # Number of training epochs\n",
                "    'batch': 16,            # Batch size (adjust based on GPU memory)\n",
                "    'imgsz': 640,           # Input image size\n",
                "    \n",
                "    # Optimizer\n",
                "    'optimizer': 'AdamW',   # Optimizer choice\n",
                "    'lr0': 0.01,            # Initial learning rate\n",
                "    'lrf': 0.01,            # Final learning rate factor\n",
                "    \n",
                "    # Augmentation\n",
                "    'augment': True,        # Enable augmentation\n",
                "    'hsv_h': 0.015,         # Hue augmentation\n",
                "    'hsv_s': 0.7,           # Saturation augmentation\n",
                "    'hsv_v': 0.4,           # Value augmentation\n",
                "    'flipud': 0.5,          # Vertical flip probability\n",
                "    'fliplr': 0.5,          # Horizontal flip probability\n",
                "    'mosaic': 1.0,          # Mosaic augmentation\n",
                "    \n",
                "    # Regularization\n",
                "    'weight_decay': 0.0005, # L2 regularization\n",
                "    \n",
                "    # Output\n",
                "    'project': str(MODELS_DIR),\n",
                "    'name': 'waste_yolo11n',\n",
                "    'exist_ok': True,\n",
                "    \n",
                "    # Performance\n",
                "    'device': 0,            # GPU device (0 for first GPU, 'cpu' for CPU)\n",
                "    'workers': 4,           # Number of data loading workers\n",
                "    \n",
                "    # Logging\n",
                "    'verbose': True,\n",
                "    'plots': True,          # Generate training plots\n",
                "}\n",
                "\n",
                "print(\"‚úÖ Training Configuration:\")\n",
                "print(\"=\"*50)\n",
                "for key, value in train_config.items():\n",
                "    print(f\"   {key:15}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save configuration\n",
                "config_path = PROJECT_ROOT / 'configs' / 'train_config.yaml'\n",
                "config_path.parent.mkdir(exist_ok=True)\n",
                "\n",
                "with open(config_path, 'w') as f:\n",
                "    yaml.dump(train_config, f, default_flow_style=False)\n",
                "\n",
                "print(f\"‚úÖ Configuration saved: {config_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 4: Quick Validation Test\n",
                "\n",
                "Test model inference before training:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test inference on sample image\n",
                "from PIL import Image\n",
                "\n",
                "# Get sample image\n",
                "sample_images = list((DATA_DIR / 'images' / 'train').glob('*.jpg'))[:1]\n",
                "\n",
                "if sample_images:\n",
                "    sample_path = sample_images[0]\n",
                "    print(f\"\\nüñºÔ∏è Testing inference on: {sample_path.name}\")\n",
                "    \n",
                "    # Run inference (pre-trained on COCO)\n",
                "    results = model.predict(source=str(sample_path), conf=0.25, save=False)\n",
                "    \n",
                "    print(f\"\\n‚úÖ Inference completed!\")\n",
                "    print(f\"   Detections: {len(results[0].boxes)}\")\n",
                "    \n",
                "    # Display\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "    \n",
                "    # Original\n",
                "    img = Image.open(sample_path)\n",
                "    axes[0].imshow(img)\n",
                "    axes[0].set_title('Original Image')\n",
                "    axes[0].axis('off')\n",
                "    \n",
                "    # With detections\n",
                "    result_img = results[0].plot()\n",
                "    axes[1].imshow(result_img)\n",
                "    axes[1].set_title('Pre-trained Model Detections (COCO)')\n",
                "    axes[1].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'pretrained_inference.png', dpi=150)\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"‚ùå No sample images found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 5: Training Script Template\n",
                "\n",
                "Ready-to-run training code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# TRAINING SCRIPT (Run this to train)\n",
                "# ============================================================\n",
                "\n",
                "def train_model(config):\n",
                "    \"\"\"\n",
                "    Train YOLOv11 on waste classification dataset.\n",
                "    \n",
                "    Args:\n",
                "        config: Training configuration dictionary\n",
                "    \n",
                "    Returns:\n",
                "        Training results\n",
                "    \"\"\"\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"üöÄ STARTING YOLOV11 TRAINING\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # Load model\n",
                "    model = YOLO('yolo11n.pt')\n",
                "    \n",
                "    # Train\n",
                "    results = model.train(**config)\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"‚úÖ TRAINING COMPLETE!\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    return results\n",
                "\n",
                "# Uncomment to train:\n",
                "# results = train_model(train_config)\n",
                "\n",
                "print(\"\\nüìù Training function ready!\")\n",
                "print(\"   Uncomment the last line to start training.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Summary\n",
                "\n",
                "### Setup Complete:\n",
                "1. ‚úÖ Dataset verified\n",
                "2. ‚úÖ YOLOv11 nano model loaded\n",
                "3. ‚úÖ Training configuration prepared\n",
                "4. ‚úÖ Inference tested\n",
                "5. ‚úÖ Training script ready\n",
                "\n",
                "### Key Files:\n",
                "- `data/processed/dataset.yaml` - Dataset config\n",
                "- `configs/train_config.yaml` - Training config\n",
                "- `models/waste_yolo11n/` - Training outputs\n",
                "\n",
                "### Next: Task 10 - Model Training!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TASK 9 COMPLETE: YOLOv11 Setup\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüìã What was accomplished:\")\n",
                "print(\"   ‚úì Dataset structure verified\")\n",
                "print(\"   ‚úì YOLOv11 model loaded\")\n",
                "print(\"   ‚úì Training config created\")\n",
                "print(\"   ‚úì Pre-training inference tested\")\n",
                "print(\"   ‚úì Training script prepared\")\n",
                "print(\"\\n‚û°Ô∏è Ready for Task 10: Model Configuration\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}