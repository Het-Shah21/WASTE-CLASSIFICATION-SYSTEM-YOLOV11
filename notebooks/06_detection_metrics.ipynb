{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Task 6: Object Detection Concepts and Metrics\n",
                "\n",
                "## üéØ Objective\n",
                "Implement and understand all key object detection metrics used in YOLO evaluation.\n",
                "\n",
                "### ML Rules Applied:\n",
                "- **Rule #2**: First, design and implement metrics\n",
                "- **Rule #13**: Choose a simple, observable metric\n",
                "- **Rule #24**: Measure the delta between models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.patches as patches\n",
                "from pathlib import Path\n",
                "\n",
                "np.random.seed(42)\n",
                "PROJECT_ROOT = Path(r\"D:\\het\\SELF\\RP\\YOLO-V11-PRO\")\n",
                "print(\"‚úÖ Libraries imported (NumPy only!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: Intersection over Union (IoU)\n",
                "\n",
                "## üìê Mathematical Definition\n",
                "\n",
                "IoU measures the overlap between two bounding boxes:\n",
                "\n",
                "$$\n",
                "IoU = \\frac{|A \\cap B|}{|A \\cup B|} = \\frac{\\text{Intersection Area}}{\\text{Union Area}}\n",
                "$$\n",
                "\n",
                "$$\n",
                "IoU = \\frac{\\text{Intersection}}{\\text{Area}_A + \\text{Area}_B - \\text{Intersection}}\n",
                "$$\n",
                "\n",
                "**IoU Properties:**\n",
                "- Range: [0, 1]\n",
                "- IoU = 1: Perfect overlap\n",
                "- IoU = 0: No overlap\n",
                "- IoU ‚â• 0.5: Typically considered a \"match\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# IoU CALCULATION - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def calculate_iou(box1, box2):\n",
                "    \"\"\"\n",
                "    Calculate Intersection over Union between two boxes.\n",
                "    \n",
                "    Formula: IoU = Intersection / Union\n",
                "    \n",
                "    Args:\n",
                "        box1, box2: [x1, y1, x2, y2] format (corners)\n",
                "    \n",
                "    Returns:\n",
                "        IoU value in [0, 1]\n",
                "    \"\"\"\n",
                "    # Unpack boxes\n",
                "    x1_a, y1_a, x2_a, y2_a = box1\n",
                "    x1_b, y1_b, x2_b, y2_b = box2\n",
                "    \n",
                "    # Calculate intersection coordinates\n",
                "    x1_inter = max(x1_a, x1_b)\n",
                "    y1_inter = max(y1_a, y1_b)\n",
                "    x2_inter = min(x2_a, x2_b)\n",
                "    y2_inter = min(y2_a, y2_b)\n",
                "    \n",
                "    # Calculate intersection area\n",
                "    inter_width = max(0, x2_inter - x1_inter)\n",
                "    inter_height = max(0, y2_inter - y1_inter)\n",
                "    intersection = inter_width * inter_height\n",
                "    \n",
                "    # Calculate union area\n",
                "    area_a = (x2_a - x1_a) * (y2_a - y1_a)\n",
                "    area_b = (x2_b - x1_b) * (y2_b - y1_b)\n",
                "    union = area_a + area_b - intersection\n",
                "    \n",
                "    # Calculate IoU\n",
                "    iou = intersection / (union + 1e-6)  # Avoid division by zero\n",
                "    \n",
                "    return iou\n",
                "\n",
                "# Test\n",
                "box_gt = [100, 100, 200, 200]   # Ground truth\n",
                "box_pred = [120, 110, 210, 210] # Prediction (partial overlap)\n",
                "iou = calculate_iou(box_gt, box_pred)\n",
                "print(f\"‚úÖ IoU between boxes: {iou:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize IoU\n",
                "def visualize_iou(box1, box2):\n",
                "    \"\"\"Visualize IoU between two boxes.\"\"\"\n",
                "    fig, ax = plt.subplots(figsize=(8, 8))\n",
                "    \n",
                "    # Draw boxes\n",
                "    rect1 = patches.Rectangle((box1[0], box1[1]), box1[2]-box1[0], box1[3]-box1[1],\n",
                "                              linewidth=3, edgecolor='green', facecolor='green', alpha=0.3, label='Ground Truth')\n",
                "    rect2 = patches.Rectangle((box2[0], box2[1]), box2[2]-box2[0], box2[3]-box2[1],\n",
                "                              linewidth=3, edgecolor='blue', facecolor='blue', alpha=0.3, label='Prediction')\n",
                "    \n",
                "    ax.add_patch(rect1)\n",
                "    ax.add_patch(rect2)\n",
                "    \n",
                "    # Calculate and display IoU\n",
                "    iou = calculate_iou(box1, box2)\n",
                "    \n",
                "    ax.set_xlim(0, 300)\n",
                "    ax.set_ylim(300, 0)  # Invert y\n",
                "    ax.set_title(f'IoU Visualization\\nIoU = {iou:.4f}', fontsize=14, fontweight='bold')\n",
                "    ax.legend()\n",
                "    ax.set_aspect('equal')\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'iou_visualization.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_iou(box_gt, box_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: Non-Maximum Suppression (NMS)\n",
                "\n",
                "## üìê Algorithm\n",
                "\n",
                "NMS removes redundant overlapping detections:\n",
                "\n",
                "```\n",
                "1. Sort all boxes by confidence score (descending)\n",
                "2. Select box with highest confidence\n",
                "3. Remove all boxes with IoU > threshold with selected box\n",
                "4. Repeat until no boxes remain\n",
                "```\n",
                "\n",
                "**Why needed:** A single object may trigger multiple detections."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# NON-MAXIMUM SUPPRESSION - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def nms(boxes, scores, iou_threshold=0.5):\n",
                "    \"\"\"\n",
                "    Non-Maximum Suppression (NumPy only).\n",
                "    \n",
                "    Args:\n",
                "        boxes: Array of [x1, y1, x2, y2] boxes, shape (N, 4)\n",
                "        scores: Confidence scores for each box, shape (N,)\n",
                "        iou_threshold: IoU threshold for suppression\n",
                "    \n",
                "    Returns:\n",
                "        Indices of boxes to keep\n",
                "    \"\"\"\n",
                "    if len(boxes) == 0:\n",
                "        return []\n",
                "    \n",
                "    boxes = np.array(boxes)\n",
                "    scores = np.array(scores)\n",
                "    \n",
                "    # Sort by confidence (descending)\n",
                "    sorted_indices = np.argsort(scores)[::-1]\n",
                "    \n",
                "    keep = []\n",
                "    \n",
                "    while len(sorted_indices) > 0:\n",
                "        # Keep the box with highest confidence\n",
                "        best_idx = sorted_indices[0]\n",
                "        keep.append(best_idx)\n",
                "        \n",
                "        # Remove it from consideration\n",
                "        sorted_indices = sorted_indices[1:]\n",
                "        \n",
                "        if len(sorted_indices) == 0:\n",
                "            break\n",
                "        \n",
                "        # Calculate IoU with remaining boxes\n",
                "        remaining_boxes = boxes[sorted_indices]\n",
                "        ious = np.array([calculate_iou(boxes[best_idx], box) for box in remaining_boxes])\n",
                "        \n",
                "        # Keep only boxes with IoU below threshold\n",
                "        mask = ious < iou_threshold\n",
                "        sorted_indices = sorted_indices[mask]\n",
                "    \n",
                "    return keep\n",
                "\n",
                "# Test NMS\n",
                "test_boxes = [\n",
                "    [100, 100, 200, 200],\n",
                "    [110, 105, 205, 205],  # Overlaps heavily\n",
                "    [115, 110, 210, 210],  # Overlaps heavily\n",
                "    [300, 300, 400, 400],  # Different object\n",
                "]\n",
                "test_scores = [0.9, 0.75, 0.8, 0.85]\n",
                "\n",
                "keep_indices = nms(test_boxes, test_scores, iou_threshold=0.5)\n",
                "print(f\"‚úÖ NMS kept {len(keep_indices)} out of {len(test_boxes)} boxes\")\n",
                "print(f\"   Kept indices: {keep_indices}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize NMS\n",
                "def visualize_nms(boxes, scores, keep_indices):\n",
                "    \"\"\"Visualize NMS before and after.\"\"\"\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "    \n",
                "    colors = plt.cm.tab10(np.linspace(0, 1, len(boxes)))\n",
                "    \n",
                "    # Before NMS\n",
                "    ax1 = axes[0]\n",
                "    for i, (box, score) in enumerate(zip(boxes, scores)):\n",
                "        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
                "                                 linewidth=2, edgecolor=colors[i], facecolor='none')\n",
                "        ax1.add_patch(rect)\n",
                "        ax1.text(box[0], box[1]-5, f'{score:.2f}', fontsize=10, color=colors[i])\n",
                "    ax1.set_xlim(50, 450)\n",
                "    ax1.set_ylim(450, 50)\n",
                "    ax1.set_title(f'Before NMS ({len(boxes)} boxes)', fontsize=12, fontweight='bold')\n",
                "    ax1.set_aspect('equal')\n",
                "    ax1.grid(True, alpha=0.3)\n",
                "    \n",
                "    # After NMS\n",
                "    ax2 = axes[1]\n",
                "    for i in keep_indices:\n",
                "        box = boxes[i]\n",
                "        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1],\n",
                "                                 linewidth=3, edgecolor='green', facecolor='green', alpha=0.3)\n",
                "        ax2.add_patch(rect)\n",
                "        ax2.text(box[0], box[1]-5, f'{scores[i]:.2f}', fontsize=10, color='green', fontweight='bold')\n",
                "    ax2.set_xlim(50, 450)\n",
                "    ax2.set_ylim(450, 50)\n",
                "    ax2.set_title(f'After NMS ({len(keep_indices)} boxes)', fontsize=12, fontweight='bold')\n",
                "    ax2.set_aspect('equal')\n",
                "    ax2.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.suptitle('üéØ Non-Maximum Suppression (NMS)', fontsize=14, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'nms_demo.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_nms(test_boxes, test_scores, keep_indices)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 3: Precision, Recall, F1-Score\n",
                "\n",
                "## üìê Mathematical Definitions\n",
                "\n",
                "$$\n",
                "\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{\\text{Correct Detections}}{\\text{All Detections}}\n",
                "$$\n",
                "\n",
                "$$\n",
                "\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{\\text{Correct Detections}}{\\text{All Ground Truths}}\n",
                "$$\n",
                "\n",
                "$$\n",
                "\\text{F1} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- **TP** (True Positive): Correct detection (IoU ‚â• threshold)\n",
                "- **FP** (False Positive): Wrong detection (no matching GT)\n",
                "- **FN** (False Negative): Missed object (GT not detected)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# PRECISION, RECALL, F1 - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def calculate_precision_recall(pred_boxes, gt_boxes, iou_threshold=0.5):\n",
                "    \"\"\"\n",
                "    Calculate precision and recall for object detection.\n",
                "    \n",
                "    Args:\n",
                "        pred_boxes: List of predicted boxes [x1, y1, x2, y2]\n",
                "        gt_boxes: List of ground truth boxes\n",
                "        iou_threshold: IoU threshold for matching\n",
                "    \n",
                "    Returns:\n",
                "        precision, recall, f1_score\n",
                "    \"\"\"\n",
                "    if len(pred_boxes) == 0:\n",
                "        return 0, 0, 0\n",
                "    if len(gt_boxes) == 0:\n",
                "        return 0, 0, 0\n",
                "    \n",
                "    # Track which GT boxes have been matched\n",
                "    gt_matched = [False] * len(gt_boxes)\n",
                "    \n",
                "    tp = 0  # True positives\n",
                "    fp = 0  # False positives\n",
                "    \n",
                "    for pred_box in pred_boxes:\n",
                "        best_iou = 0\n",
                "        best_gt_idx = -1\n",
                "        \n",
                "        # Find best matching GT box\n",
                "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
                "            if gt_matched[gt_idx]:\n",
                "                continue\n",
                "            \n",
                "            iou = calculate_iou(pred_box, gt_box)\n",
                "            if iou > best_iou:\n",
                "                best_iou = iou\n",
                "                best_gt_idx = gt_idx\n",
                "        \n",
                "        # Check if match is good enough\n",
                "        if best_iou >= iou_threshold:\n",
                "            tp += 1\n",
                "            gt_matched[best_gt_idx] = True\n",
                "        else:\n",
                "            fp += 1\n",
                "    \n",
                "    fn = sum(1 for matched in gt_matched if not matched)\n",
                "    \n",
                "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
                "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
                "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
                "    \n",
                "    return precision, recall, f1\n",
                "\n",
                "# Test\n",
                "gt_boxes = [[100, 100, 200, 200], [300, 300, 400, 400]]\n",
                "pred_boxes = [[105, 105, 205, 205], [305, 305, 395, 395], [500, 500, 600, 600]]  # 2 good, 1 FP\n",
                "\n",
                "p, r, f1 = calculate_precision_recall(pred_boxes, gt_boxes)\n",
                "print(f\"‚úÖ Precision: {p:.4f}\")\n",
                "print(f\"   Recall: {r:.4f}\")\n",
                "print(f\"   F1-Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 4: Mean Average Precision (mAP)\n",
                "\n",
                "## üìê Mathematical Definition\n",
                "\n",
                "**Average Precision (AP)** for one class:\n",
                "$$\n",
                "AP = \\int_0^1 p(r) \\, dr \\approx \\sum_{n} (r_{n+1} - r_n) \\cdot p_{interp}(r_{n+1})\n",
                "$$\n",
                "\n",
                "**Mean Average Precision**:\n",
                "$$\n",
                "mAP = \\frac{1}{|C|} \\sum_{c \\in C} AP_c\n",
                "$$\n",
                "\n",
                "**Common Metrics:**\n",
                "- **mAP@50**: Using IoU threshold = 0.5\n",
                "- **mAP@50-95**: Average over IoU thresholds [0.5, 0.55, ..., 0.95]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# AVERAGE PRECISION (AP) - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def calculate_ap(precisions, recalls):\n",
                "    \"\"\"\n",
                "    Calculate Average Precision from precision-recall curve.\n",
                "    \n",
                "    Uses 11-point interpolation (PASCAL VOC style).\n",
                "    \"\"\"\n",
                "    precisions = np.array(precisions)\n",
                "    recalls = np.array(recalls)\n",
                "    \n",
                "    # Sort by recall\n",
                "    sorted_idx = np.argsort(recalls)\n",
                "    recalls = recalls[sorted_idx]\n",
                "    precisions = precisions[sorted_idx]\n",
                "    \n",
                "    # 11-point interpolation\n",
                "    ap = 0\n",
                "    for t in np.linspace(0, 1, 11):\n",
                "        # Get max precision at recall >= t\n",
                "        mask = recalls >= t\n",
                "        if np.any(mask):\n",
                "            ap += np.max(precisions[mask])\n",
                "    \n",
                "    return ap / 11\n",
                "\n",
                "def calculate_map(all_predictions, all_ground_truths, iou_threshold=0.5):\n",
                "    \"\"\"\n",
                "    Calculate mAP across all classes.\n",
                "    \n",
                "    Args:\n",
                "        all_predictions: Dict {class_id: [(box, score), ...]}\n",
                "        all_ground_truths: Dict {class_id: [box, ...]}\n",
                "    \"\"\"\n",
                "    aps = []\n",
                "    \n",
                "    for class_id in all_ground_truths.keys():\n",
                "        preds = all_predictions.get(class_id, [])\n",
                "        gts = all_ground_truths[class_id]\n",
                "        \n",
                "        if len(preds) == 0 or len(gts) == 0:\n",
                "            aps.append(0)\n",
                "            continue\n",
                "        \n",
                "        # Sort predictions by score\n",
                "        preds = sorted(preds, key=lambda x: x[1], reverse=True)\n",
                "        \n",
                "        # Calculate precision/recall at each threshold\n",
                "        precisions = []\n",
                "        recalls = []\n",
                "        \n",
                "        for i in range(1, len(preds) + 1):\n",
                "            pred_boxes = [p[0] for p in preds[:i]]\n",
                "            p, r, _ = calculate_precision_recall(pred_boxes, gts, iou_threshold)\n",
                "            precisions.append(p)\n",
                "            recalls.append(r)\n",
                "        \n",
                "        ap = calculate_ap(precisions, recalls)\n",
                "        aps.append(ap)\n",
                "    \n",
                "    return np.mean(aps)\n",
                "\n",
                "print(\"‚úÖ mAP calculation functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize Precision-Recall Curve\n",
                "def plot_precision_recall_curve():\n",
                "    \"\"\"Sample precision-recall curve.\"\"\"\n",
                "    # Simulated values\n",
                "    recalls = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
                "    precisions = np.array([1.0, 0.95, 0.9, 0.85, 0.8, 0.7, 0.6, 0.5, 0.3, 0.1])\n",
                "    \n",
                "    ap = calculate_ap(precisions, recalls)\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(8, 6))\n",
                "    \n",
                "    ax.plot(recalls, precisions, 'b-', linewidth=2, marker='o', label=f'AP = {ap:.3f}')\n",
                "    ax.fill_between(recalls, precisions, alpha=0.3)\n",
                "    \n",
                "    ax.set_xlabel('Recall', fontsize=12)\n",
                "    ax.set_ylabel('Precision', fontsize=12)\n",
                "    ax.set_title('üìà Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
                "    ax.set_xlim(0, 1)\n",
                "    ax.set_ylim(0, 1)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'pr_curve.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "plot_precision_recall_curve()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Summary\n",
                "\n",
                "### Implemented Metrics (NumPy only):\n",
                "\n",
                "| Metric | Formula | Function |\n",
                "|--------|---------|----------|\n",
                "| **IoU** | Intersection/Union | `calculate_iou()` |\n",
                "| **NMS** | Suppress overlapping boxes | `nms()` |\n",
                "| **Precision** | TP/(TP+FP) | `calculate_precision_recall()` |\n",
                "| **Recall** | TP/(TP+FN) | `calculate_precision_recall()` |\n",
                "| **AP** | Area under PR curve | `calculate_ap()` |\n",
                "| **mAP** | Mean AP across classes | `calculate_map()` |\n",
                "\n",
                "### Next: Task 7 - YOLO Architecture Deep Dive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TASK 6 COMPLETE: Object Detection Metrics\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüìã Implemented (NumPy only):\")\n",
                "print(\"   ‚úì IoU calculation\")\n",
                "print(\"   ‚úì Non-Maximum Suppression (NMS)\")\n",
                "print(\"   ‚úì Precision, Recall, F1-Score\")\n",
                "print(\"   ‚úì Average Precision (AP)\")\n",
                "print(\"   ‚úì Mean Average Precision (mAP)\")\n",
                "print(\"\\n‚û°Ô∏è Ready for Task 7: YOLO Architecture\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}