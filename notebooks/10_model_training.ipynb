{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ‚öôÔ∏è Task 10: Model Configuration and Training\n",
                "\n",
                "## üéØ Objective\n",
                "Configure YOLOv11 specifically for our 2-class waste classification task and execute training.\n",
                "\n",
                "---\n",
                "\n",
                "## üìö Training Strategy\n",
                "\n",
                "### Transfer Learning Approach:\n",
                "1. Start with pre-trained COCO weights\n",
                "2. Fine-tune on waste dataset\n",
                "3. Monitor validation metrics\n",
                "\n",
                "### ML Rules Applied:\n",
                "- **Rule #4**: Keep the first model simple\n",
                "- **Rule #5**: Test infrastructure separately from ML\n",
                "- **Rule #23**: You are not a typical consumer of your model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "import yaml\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from datetime import datetime\n",
                "\n",
                "# Ultralytics\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# Project paths\n",
                "PROJECT_ROOT = Path(r\"D:\\het\\SELF\\RP\\YOLO-V11-PRO\")\n",
                "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
                "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
                "CONFIGS_DIR = PROJECT_ROOT / \"configs\"\n",
                "\n",
                "# Create directories\n",
                "MODELS_DIR.mkdir(exist_ok=True)\n",
                "CONFIGS_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(\"‚úÖ Setup complete!\")\n",
                "print(f\"   Data: {DATA_DIR}\")\n",
                "print(f\"   Models: {MODELS_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: Waste Classification Config\n",
                "\n",
                "Our specific configuration for binary waste classification:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# WASTE CLASSIFICATION TRAINING CONFIG\n",
                "# ============================================================\n",
                "\n",
                "# Dataset YAML\n",
                "dataset_yaml = DATA_DIR / 'dataset.yaml'\n",
                "\n",
                "# Model name with timestamp\n",
                "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
                "run_name = f\"waste_yolo11n_{timestamp}\"\n",
                "\n",
                "# Training configuration\n",
                "training_args = {\n",
                "    # === DATASET ===\n",
                "    'data': str(dataset_yaml),\n",
                "    \n",
                "    # === TRAINING ===\n",
                "    'epochs': 100,              # Epochs (100 for proper training)\n",
                "    'patience': 20,             # Early stopping patience\n",
                "    'batch': 16,                # Batch size\n",
                "    'imgsz': 640,               # Image size\n",
                "    \n",
                "    # === OPTIMIZER ===\n",
                "    'optimizer': 'AdamW',\n",
                "    'lr0': 0.01,                # Initial LR\n",
                "    'lrf': 0.01,                # Final LR = lr0 * lrf\n",
                "    'momentum': 0.937,\n",
                "    'weight_decay': 0.0005,\n",
                "    \n",
                "    # === AUGMENTATION ===\n",
                "    'augment': True,\n",
                "    'hsv_h': 0.015,             # Hue\n",
                "    'hsv_s': 0.7,               # Saturation\n",
                "    'hsv_v': 0.4,               # Value\n",
                "    'degrees': 10,              # Rotation\n",
                "    'translate': 0.1,           # Translation\n",
                "    'scale': 0.5,               # Scale\n",
                "    'shear': 2.0,               # Shear\n",
                "    'flipud': 0.5,              # Vertical flip\n",
                "    'fliplr': 0.5,              # Horizontal flip\n",
                "    'mosaic': 1.0,              # Mosaic\n",
                "    'mixup': 0.1,               # MixUp\n",
                "    \n",
                "    # === OUTPUT ===\n",
                "    'project': str(MODELS_DIR),\n",
                "    'name': run_name,\n",
                "    'exist_ok': True,\n",
                "    \n",
                "    # === PERFORMANCE ===\n",
                "    'device': 0,                # GPU 0\n",
                "    'workers': 4,\n",
                "    'amp': True,                # Mixed precision\n",
                "    \n",
                "    # === LOGGING ===\n",
                "    'verbose': True,\n",
                "    'plots': True,\n",
                "    'save': True,\n",
                "    'save_period': 10,          # Save every 10 epochs\n",
                "}\n",
                "\n",
                "print(\"\\nüìã Training Configuration:\")\n",
                "print(\"=\"*55)\n",
                "print(f\"{'Parameter':<20} {'Value':<30}\")\n",
                "print(\"-\"*55)\n",
                "for k, v in training_args.items():\n",
                "    print(f\"{k:<20} {str(v):<30}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save training config\n",
                "config_file = CONFIGS_DIR / f'{run_name}_config.yaml'\n",
                "with open(config_file, 'w') as f:\n",
                "    yaml.dump(training_args, f, default_flow_style=False)\n",
                "print(f\"\\n‚úÖ Config saved: {config_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: Load Model and Train\n",
                "\n",
                "Now let's train the model!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# LOAD YOLOV11 MODEL\n",
                "# ============================================================\n",
                "\n",
                "# Load pre-trained YOLOv11 nano\n",
                "model = YOLO('yolo11n.pt')\n",
                "\n",
                "print(\"‚úÖ Model loaded: YOLOv11 Nano\")\n",
                "print(\"\\nüìä Pre-trained on: COCO (80 classes)\")\n",
                "print(\"üéØ Fine-tuning for: Waste (2 classes)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# TRAIN THE MODEL\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üöÄ STARTING TRAINING\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nüìÖ Run: {run_name}\")\n",
                "print(f\"üìÅ Output: {MODELS_DIR / run_name}\")\n",
                "print(\"\\n‚è≥ Training in progress...\\n\")\n",
                "\n",
                "# Train!\n",
                "results = model.train(**training_args)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TRAINING COMPLETE!\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 3: Evaluate Results\n",
                "\n",
                "After training, let's analyze the results:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# ANALYZE TRAINING RESULTS\n",
                "# ============================================================\n",
                "\n",
                "# Best model path\n",
                "best_model_path = MODELS_DIR / run_name / 'weights' / 'best.pt'\n",
                "last_model_path = MODELS_DIR / run_name / 'weights' / 'last.pt'\n",
                "\n",
                "print(\"\\nüìä Training Results:\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "if best_model_path.exists():\n",
                "    print(f\"   ‚úÖ Best weights: {best_model_path}\")\n",
                "else:\n",
                "    print(f\"   ‚ö†Ô∏è Best weights not found yet\")\n",
                "\n",
                "if last_model_path.exists():\n",
                "    print(f\"   ‚úÖ Last weights: {last_model_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load training plots if available\n",
                "results_dir = MODELS_DIR / run_name\n",
                "\n",
                "plots = [\n",
                "    'results.png',\n",
                "    'confusion_matrix.png',\n",
                "    'F1_curve.png',\n",
                "    'PR_curve.png',\n",
                "]\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
                "\n",
                "for ax, plot_name in zip(axes.flat, plots):\n",
                "    plot_path = results_dir / plot_name\n",
                "    if plot_path.exists():\n",
                "        img = plt.imread(plot_path)\n",
                "        ax.imshow(img)\n",
                "        ax.set_title(plot_name.replace('.png', '').replace('_', ' '))\n",
                "    else:\n",
                "        ax.text(0.5, 0.5, f'{plot_name}\\n(Not available)', ha='center', va='center')\n",
                "    ax.axis('off')\n",
                "\n",
                "plt.suptitle('üìà Training Results', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'training_results.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# VALIDATE MODEL\n",
                "# ============================================================\n",
                "\n",
                "if best_model_path.exists():\n",
                "    print(\"\\nüîç Validating best model...\")\n",
                "    \n",
                "    best_model = YOLO(str(best_model_path))\n",
                "    val_results = best_model.val(data=str(dataset_yaml))\n",
                "    \n",
                "    print(\"\\nüìä Validation Metrics:\")\n",
                "    print(\"=\"*50)\n",
                "    print(f\"   mAP@50:    {val_results.box.map50:.4f}\")\n",
                "    print(f\"   mAP@50-95: {val_results.box.map:.4f}\")\n",
                "    print(f\"   Precision: {val_results.box.mp:.4f}\")\n",
                "    print(f\"   Recall:    {val_results.box.mr:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# TEST INFERENCE\n",
                "# ============================================================\n",
                "\n",
                "from PIL import Image\n",
                "\n",
                "# Get test images\n",
                "test_images = list((DATA_DIR / 'images' / 'val').glob('*.jpg'))[:6]\n",
                "\n",
                "if best_model_path.exists() and test_images:\n",
                "    best_model = YOLO(str(best_model_path))\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "    fig.suptitle('üéØ Model Predictions on Validation Set', fontsize=14, fontweight='bold')\n",
                "    \n",
                "    for ax, img_path in zip(axes.flat, test_images):\n",
                "        # Run inference\n",
                "        results = best_model.predict(source=str(img_path), conf=0.25, save=False, verbose=False)\n",
                "        \n",
                "        # Plot\n",
                "        result_img = results[0].plot()\n",
                "        ax.imshow(result_img)\n",
                "        ax.set_title(img_path.name[:25])\n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'model_predictions.png', dpi=150)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 4: Export Model\n",
                "\n",
                "Export for deployment:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export to different formats\n",
                "if best_model_path.exists():\n",
                "    best_model = YOLO(str(best_model_path))\n",
                "    \n",
                "    print(\"\\nüì¶ Exporting model...\")\n",
                "    \n",
                "    # Export to ONNX (cross-platform)\n",
                "    onnx_path = best_model.export(format='onnx')\n",
                "    print(f\"   ‚úÖ ONNX: {onnx_path}\")\n",
                "    \n",
                "    # The PyTorch model is already saved\n",
                "    print(f\"   ‚úÖ PyTorch: {best_model_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Summary\n",
                "\n",
                "### Training Complete:\n",
                "- ‚úÖ Model trained on waste dataset\n",
                "- ‚úÖ Best weights saved\n",
                "- ‚úÖ Validation metrics computed\n",
                "- ‚úÖ Model exported\n",
                "\n",
                "### Key Files:\n",
                "- `models/{run_name}/weights/best.pt` - Best model\n",
                "- `models/{run_name}/results.png` - Training curves\n",
                "- `models/{run_name}/confusion_matrix.png` - Confusion matrix\n",
                "\n",
                "### Next: Task 11 - Evaluation & Deployment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TASK 10 COMPLETE: Model Training\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüìã Accomplished:\")\n",
                "print(\"   ‚úì Training configuration set\")\n",
                "print(\"   ‚úì Model trained on waste dataset\") \n",
                "print(\"   ‚úì Training metrics plotted\")\n",
                "print(\"   ‚úì Model validated\")\n",
                "print(\"   ‚úì Inference tested\")\n",
                "print(\"   ‚úì Model exported\")\n",
                "print(\"\\n‚û°Ô∏è Ready for Deployment!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}