{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìâ Task 8: Loss Function Mathematics\n",
                "\n",
                "## üéØ Objective\n",
                "Understand and implement the loss functions used in YOLO training from scratch.\n",
                "\n",
                "---\n",
                "\n",
                "## üìö Why Loss Functions Matter\n",
                "\n",
                "The loss function guides learning by measuring how wrong predictions are:\n",
                "- **Lower loss** = Better predictions\n",
                "- **Gradient of loss** = Direction to improve\n",
                "\n",
                "### ML Rules Applied:\n",
                "- **Rule #21**: The number you optimize is not the one you want to maximize\n",
                "- **Rule #22**: Keep your code modular for fast experimentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "np.random.seed(42)\n",
                "PROJECT_ROOT = Path(r\"D:\\het\\SELF\\RP\\YOLO-V11-PRO\")\n",
                "print(\"‚úÖ Libraries imported (NumPy only!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: YOLO Total Loss\n",
                "\n",
                "## üìê YOLO Loss Formula\n",
                "\n",
                "$$\n",
                "\\mathcal{L}_{total} = \\lambda_{box} \\cdot \\mathcal{L}_{box} + \\lambda_{cls} \\cdot \\mathcal{L}_{cls} + \\lambda_{obj} \\cdot \\mathcal{L}_{obj}\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- **L_box**: Bounding box regression loss\n",
                "- **L_cls**: Classification loss\n",
                "- **L_obj**: Objectness/confidence loss\n",
                "- **Œª**: Weight coefficients\n",
                "\n",
                "```\n",
                "YOLO Predictions\n",
                "       ‚îÇ\n",
                "       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "       ‚îÇ              ‚îÇ              ‚îÇ\n",
                "       ‚Üì              ‚Üì              ‚Üì\n",
                "   Box Loss      Class Loss     Obj Loss\n",
                "   (CIoU)        (BCE/Focal)    (BCE)\n",
                "       ‚îÇ              ‚îÇ              ‚îÇ\n",
                "       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "                      ‚îÇ\n",
                "                Total Loss\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: Binary Cross-Entropy (BCE) Loss\n",
                "\n",
                "## üìê Mathematical Definition\n",
                "\n",
                "Used for objectness and classification (per-class):\n",
                "\n",
                "$$\n",
                "BCE(y, \\hat{y}) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- **y**: Ground truth (0 or 1)\n",
                "- **≈∑**: Predicted probability [0, 1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# BINARY CROSS-ENTROPY - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def binary_cross_entropy(y_true, y_pred, epsilon=1e-7):\n",
                "    \"\"\"\n",
                "    Binary Cross-Entropy Loss (NumPy).\n",
                "    \n",
                "    Formula: BCE = -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)]\n",
                "    \n",
                "    Args:\n",
                "        y_true: Ground truth labels (0 or 1)\n",
                "        y_pred: Predicted probabilities [0, 1]\n",
                "        epsilon: Small value to prevent log(0)\n",
                "    \n",
                "    Returns:\n",
                "        BCE loss value\n",
                "    \"\"\"\n",
                "    # Clip predictions to prevent log(0)\n",
                "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
                "    \n",
                "    # Calculate BCE\n",
                "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
                "    \n",
                "    return np.mean(loss)\n",
                "\n",
                "# Test\n",
                "y_true = np.array([1, 0, 1, 1, 0])\n",
                "y_pred = np.array([0.9, 0.1, 0.8, 0.7, 0.3])\n",
                "\n",
                "bce = binary_cross_entropy(y_true, y_pred)\n",
                "print(f\"‚úÖ BCE Loss: {bce:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize BCE\n",
                "def visualize_bce():\n",
                "    \"\"\"Visualize BCE loss behavior.\"\"\"\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    \n",
                "    p = np.linspace(0.01, 0.99, 100)\n",
                "    \n",
                "    # When y=1 (should predict high)\n",
                "    loss_y1 = -np.log(p)\n",
                "    axes[0].plot(p, loss_y1, 'b-', linewidth=2)\n",
                "    axes[0].set_xlabel('Predicted Probability ≈∑')\n",
                "    axes[0].set_ylabel('Loss')\n",
                "    axes[0].set_title('BCE when y=1 (should predict HIGH)')\n",
                "    axes[0].axvline(x=1, color='g', linestyle='--', label='Target')\n",
                "    axes[0].legend()\n",
                "    axes[0].grid(True, alpha=0.3)\n",
                "    \n",
                "    # When y=0 (should predict low)\n",
                "    loss_y0 = -np.log(1 - p)\n",
                "    axes[1].plot(p, loss_y0, 'r-', linewidth=2)\n",
                "    axes[1].set_xlabel('Predicted Probability ≈∑')\n",
                "    axes[1].set_ylabel('Loss')\n",
                "    axes[1].set_title('BCE when y=0 (should predict LOW)')\n",
                "    axes[1].axvline(x=0, color='g', linestyle='--', label='Target')\n",
                "    axes[1].legend()\n",
                "    axes[1].grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.suptitle('üìâ Binary Cross-Entropy Behavior', fontsize=14, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'bce_loss.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_bce()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 3: Focal Loss\n",
                "\n",
                "## üìê Mathematical Definition\n",
                "\n",
                "Focal Loss addresses class imbalance by down-weighting easy examples:\n",
                "\n",
                "$$\n",
                "FL(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t)\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- **Œ≥** (gamma): Focusing parameter (typically 2)\n",
                "- **Œ±** (alpha): Class weight\n",
                "- **(1-p_t)^Œ≥**: Modulating factor that reduces loss for easy examples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# FOCAL LOSS - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25, epsilon=1e-7):\n",
                "    \"\"\"\n",
                "    Focal Loss for handling class imbalance.\n",
                "    \n",
                "    Formula: FL = -Œ±(1-p_t)^Œ≥ √ó log(p_t)\n",
                "    \n",
                "    Args:\n",
                "        y_true: Ground truth labels\n",
                "        y_pred: Predicted probabilities\n",
                "        gamma: Focusing parameter (reduces easy example loss)\n",
                "        alpha: Class weight\n",
                "    \n",
                "    Returns:\n",
                "        Focal loss value\n",
                "    \"\"\"\n",
                "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
                "    \n",
                "    # p_t = p if y=1, else 1-p\n",
                "    p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
                "    \n",
                "    # Alpha weighting\n",
                "    alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
                "    \n",
                "    # Focal weight: (1 - p_t)^gamma\n",
                "    focal_weight = (1 - p_t) ** gamma\n",
                "    \n",
                "    # Focal loss\n",
                "    loss = -alpha_t * focal_weight * np.log(p_t)\n",
                "    \n",
                "    return np.mean(loss)\n",
                "\n",
                "# Compare BCE vs Focal\n",
                "fl = focal_loss(y_true, y_pred)\n",
                "print(f\"‚úÖ BCE Loss: {bce:.4f}\")\n",
                "print(f\"‚úÖ Focal Loss: {fl:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize Focal vs BCE\n",
                "def visualize_focal_vs_bce():\n",
                "    \"\"\"Compare Focal Loss vs BCE.\"\"\"\n",
                "    fig, ax = plt.subplots(figsize=(10, 6))\n",
                "    \n",
                "    p = np.linspace(0.01, 0.99, 100)\n",
                "    \n",
                "    # BCE (when y=1)\n",
                "    bce = -np.log(p)\n",
                "    ax.plot(p, bce, 'b-', linewidth=2, label='BCE')\n",
                "    \n",
                "    # Focal Loss with different gamma\n",
                "    for gamma in [0.5, 1, 2, 5]:\n",
                "        focal = -(1 - p)**gamma * np.log(p)\n",
                "        ax.plot(p, focal, '--', linewidth=1.5, label=f'Focal Œ≥={gamma}')\n",
                "    \n",
                "    ax.set_xlabel('Predicted Probability (for positive class)', fontsize=12)\n",
                "    ax.set_ylabel('Loss', fontsize=12)\n",
                "    ax.set_title('üìâ BCE vs Focal Loss (when y=1)', fontsize=14, fontweight='bold')\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    ax.set_ylim(0, 5)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'focal_vs_bce.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "visualize_focal_vs_bce()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 4: IoU-Based Box Loss (CIoU)\n",
                "\n",
                "## üìê Evolution of Box Loss\n",
                "\n",
                "### 1. L1/L2 Loss (Basic)\n",
                "$$L_{box} = \\sum |x - \\hat{x}| + |y - \\hat{y}| + |w - \\hat{w}| + |h - \\hat{h}|$$\n",
                "\n",
                "**Problem**: Doesn't consider box overlap directly.\n",
                "\n",
                "### 2. IoU Loss\n",
                "$$L_{IoU} = 1 - IoU$$\n",
                "\n",
                "**Problem**: No gradient when boxes don't overlap.\n",
                "\n",
                "### 3. GIoU (Generalized IoU)\n",
                "$$GIoU = IoU - \\frac{|C - A \\cup B|}{|C|}$$\n",
                "\n",
                "Where C is the smallest enclosing box.\n",
                "\n",
                "### 4. CIoU (Complete IoU) - Used in YOLO\n",
                "$$CIoU = IoU - \\frac{\\rho^2(b, b^{gt})}{c^2} - \\alpha v$$\n",
                "\n",
                "Where:\n",
                "- **œÅ**: Euclidean distance between centers\n",
                "- **c**: Diagonal of smallest enclosing box\n",
                "- **v**: Aspect ratio consistency\n",
                "- **Œ±**: Trade-off parameter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# CIoU LOSS - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def calculate_iou(box1, box2):\n",
                "    \"\"\"Calculate IoU between two boxes [x1,y1,x2,y2].\"\"\"\n",
                "    x1_a, y1_a, x2_a, y2_a = box1\n",
                "    x1_b, y1_b, x2_b, y2_b = box2\n",
                "    \n",
                "    inter_x1 = max(x1_a, x1_b)\n",
                "    inter_y1 = max(y1_a, y1_b)\n",
                "    inter_x2 = min(x2_a, x2_b)\n",
                "    inter_y2 = min(y2_a, y2_b)\n",
                "    \n",
                "    inter_w = max(0, inter_x2 - inter_x1)\n",
                "    inter_h = max(0, inter_y2 - inter_y1)\n",
                "    inter_area = inter_w * inter_h\n",
                "    \n",
                "    area_a = (x2_a - x1_a) * (y2_a - y1_a)\n",
                "    area_b = (x2_b - x1_b) * (y2_b - y1_b)\n",
                "    union_area = area_a + area_b - inter_area\n",
                "    \n",
                "    return inter_area / (union_area + 1e-6)\n",
                "\n",
                "def ciou_loss(box_pred, box_gt):\n",
                "    \"\"\"\n",
                "    Complete IoU Loss (NumPy).\n",
                "    \n",
                "    Formula: CIoU = IoU - (d¬≤/c¬≤) - Œ±v\n",
                "    \n",
                "    Args:\n",
                "        box_pred: Predicted [x1, y1, x2, y2]\n",
                "        box_gt: Ground truth [x1, y1, x2, y2]\n",
                "    \n",
                "    Returns:\n",
                "        CIoU loss value\n",
                "    \"\"\"\n",
                "    # Basic IoU\n",
                "    iou = calculate_iou(box_pred, box_gt)\n",
                "    \n",
                "    # Box centers\n",
                "    center_pred = [(box_pred[0] + box_pred[2])/2, (box_pred[1] + box_pred[3])/2]\n",
                "    center_gt = [(box_gt[0] + box_gt[2])/2, (box_gt[1] + box_gt[3])/2]\n",
                "    \n",
                "    # Distance between centers (œÅ¬≤)\n",
                "    rho2 = (center_pred[0] - center_gt[0])**2 + (center_pred[1] - center_gt[1])**2\n",
                "    \n",
                "    # Smallest enclosing box\n",
                "    enclose_x1 = min(box_pred[0], box_gt[0])\n",
                "    enclose_y1 = min(box_pred[1], box_gt[1])\n",
                "    enclose_x2 = max(box_pred[2], box_gt[2])\n",
                "    enclose_y2 = max(box_pred[3], box_gt[3])\n",
                "    \n",
                "    # Diagonal of enclosing box (c¬≤)\n",
                "    c2 = (enclose_x2 - enclose_x1)**2 + (enclose_y2 - enclose_y1)**2 + 1e-6\n",
                "    \n",
                "    # Width and height\n",
                "    w_pred = box_pred[2] - box_pred[0]\n",
                "    h_pred = box_pred[3] - box_pred[1]\n",
                "    w_gt = box_gt[2] - box_gt[0]\n",
                "    h_gt = box_gt[3] - box_gt[1]\n",
                "    \n",
                "    # Aspect ratio term (v)\n",
                "    v = (4 / np.pi**2) * (np.arctan(w_gt / (h_gt + 1e-6)) - np.arctan(w_pred / (h_pred + 1e-6)))**2\n",
                "    \n",
                "    # Trade-off parameter (Œ±)\n",
                "    alpha = v / (1 - iou + v + 1e-6)\n",
                "    \n",
                "    # CIoU\n",
                "    ciou = iou - (rho2 / c2) - alpha * v\n",
                "    \n",
                "    return 1 - ciou  # Loss = 1 - CIoU\n",
                "\n",
                "# Test\n",
                "box_pred = [100, 100, 200, 200]\n",
                "box_gt = [110, 105, 195, 205]\n",
                "\n",
                "ciou = ciou_loss(box_pred, box_gt)\n",
                "print(f\"‚úÖ CIoU Loss: {ciou:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 5: Complete YOLO Loss\n",
                "\n",
                "Combining all components:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# COMPLETE YOLO LOSS - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "class YOLOLoss:\n",
                "    \"\"\"\n",
                "    Complete YOLO Loss Function (NumPy only).\n",
                "    \n",
                "    Total Loss = Œª_box √ó L_box + Œª_cls √ó L_cls + Œª_obj √ó L_obj\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, lambda_box=0.05, lambda_cls=0.5, lambda_obj=1.0):\n",
                "        self.lambda_box = lambda_box\n",
                "        self.lambda_cls = lambda_cls\n",
                "        self.lambda_obj = lambda_obj\n",
                "    \n",
                "    def box_loss(self, pred_boxes, gt_boxes):\n",
                "        \"\"\"CIoU-based box regression loss.\"\"\"\n",
                "        losses = [ciou_loss(p, g) for p, g in zip(pred_boxes, gt_boxes)]\n",
                "        return np.mean(losses) if losses else 0\n",
                "    \n",
                "    def cls_loss(self, pred_cls, gt_cls):\n",
                "        \"\"\"Classification loss (BCE or Focal).\"\"\"\n",
                "        return binary_cross_entropy(gt_cls, pred_cls)\n",
                "    \n",
                "    def obj_loss(self, pred_obj, gt_obj):\n",
                "        \"\"\"Objectness loss (BCE).\"\"\"\n",
                "        return binary_cross_entropy(gt_obj, pred_obj)\n",
                "    \n",
                "    def __call__(self, predictions, targets):\n",
                "        \"\"\"\n",
                "        Calculate total loss.\n",
                "        \n",
                "        Args:\n",
                "            predictions: Dict with 'boxes', 'classes', 'objectness'\n",
                "            targets: Dict with 'boxes', 'classes', 'objectness'\n",
                "        \"\"\"\n",
                "        l_box = self.box_loss(predictions['boxes'], targets['boxes'])\n",
                "        l_cls = self.cls_loss(predictions['classes'], targets['classes'])\n",
                "        l_obj = self.obj_loss(predictions['objectness'], targets['objectness'])\n",
                "        \n",
                "        total = (self.lambda_box * l_box + \n",
                "                self.lambda_cls * l_cls + \n",
                "                self.lambda_obj * l_obj)\n",
                "        \n",
                "        return {\n",
                "            'total': total,\n",
                "            'box_loss': l_box,\n",
                "            'cls_loss': l_cls,\n",
                "            'obj_loss': l_obj\n",
                "        }\n",
                "\n",
                "# Test\n",
                "loss_fn = YOLOLoss()\n",
                "\n",
                "predictions = {\n",
                "    'boxes': [[100, 100, 200, 200], [300, 300, 400, 400]],\n",
                "    'classes': np.array([0.9, 0.8]),\n",
                "    'objectness': np.array([0.95, 0.9])\n",
                "}\n",
                "\n",
                "targets = {\n",
                "    'boxes': [[105, 105, 195, 195], [305, 305, 395, 395]],\n",
                "    'classes': np.array([1, 1]),\n",
                "    'objectness': np.array([1, 1])\n",
                "}\n",
                "\n",
                "losses = loss_fn(predictions, targets)\n",
                "print(f\"\\n‚úÖ YOLO Loss Components:\")\n",
                "print(f\"   Box Loss: {losses['box_loss']:.4f}\")\n",
                "print(f\"   Cls Loss: {losses['cls_loss']:.4f}\")\n",
                "print(f\"   Obj Loss: {losses['obj_loss']:.4f}\")\n",
                "print(f\"   TOTAL: {losses['total']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Summary\n",
                "\n",
                "### Loss Functions Implemented:\n",
                "\n",
                "| Loss | Formula | Use |\n",
                "|------|---------|-----|\n",
                "| **BCE** | -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)] | Classification, Objectness |\n",
                "| **Focal** | -Œ±(1-p_t)^Œ≥¬∑log(p_t) | Imbalanced classification |\n",
                "| **CIoU** | 1 - IoU + d¬≤/c¬≤ + Œ±v | Box regression |\n",
                "\n",
                "### YOLO Total Loss:\n",
                "$$\\mathcal{L} = \\lambda_{box} \\cdot CIoU + \\lambda_{cls} \\cdot BCE + \\lambda_{obj} \\cdot BCE$$\n",
                "\n",
                "### Next: Phase 3 - Model Development!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TASK 8 COMPLETE: Loss Function Mathematics\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüìã Implemented (NumPy only):\")\n",
                "print(\"   ‚úì Binary Cross-Entropy (BCE)\")\n",
                "print(\"   ‚úì Focal Loss\")\n",
                "print(\"   ‚úì CIoU Loss\")\n",
                "print(\"   ‚úì Complete YOLOLoss class\")\n",
                "print(\"\\nüéâ Phase 2 Complete (Theory)!\")\n",
                "print(\"\\n‚û°Ô∏è Ready for Phase 3: Model Development\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}