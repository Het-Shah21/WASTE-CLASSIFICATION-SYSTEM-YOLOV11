{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† Task 5: CNN Fundamentals with NumPy\n",
                "\n",
                "## üéØ Objective\n",
                "Implement core CNN components from scratch using NumPy to understand the mathematical foundations before using YOLOv11.\n",
                "\n",
                "---\n",
                "\n",
                "## üìö Why This Matters\n",
                "\n",
                "Before using complex frameworks, understanding the math helps you:\n",
                "1. **Debug effectively** - Know what's happening inside\n",
                "2. **Optimize performance** - Understand bottlenecks\n",
                "3. **Customize architectures** - Modify with confidence\n",
                "\n",
                "### ML Rules Applied:\n",
                "- **Rule #14**: Starting with an interpretable model makes debugging easier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from pathlib import Path\n",
                "\n",
                "np.random.seed(42)\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "PROJECT_ROOT = Path(r\"D:\\het\\SELF\\RP\\YOLO-V11-PRO\")\n",
                "print(\"‚úÖ Libraries imported (NumPy only - no PyTorch!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: Convolution Operation\n",
                "\n",
                "## üìê Mathematical Definition\n",
                "\n",
                "**2D Discrete Convolution:**\n",
                "$$\n",
                "(I * K)[i,j] = \\sum_{m=0}^{k_h-1} \\sum_{n=0}^{k_w-1} I[i+m, j+n] \\cdot K[m,n]\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- **I** = Input image (H √ó W)\n",
                "- **K** = Kernel/Filter (k_h √ó k_w)\n",
                "- ***** = Convolution operation\n",
                "\n",
                "**Output Size:**\n",
                "$$\n",
                "O_h = \\frac{H - k_h + 2P}{S} + 1 \\quad\\quad O_w = \\frac{W - k_w + 2P}{S} + 1\n",
                "$$\n",
                "\n",
                "Where: P = padding, S = stride"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# 2D CONVOLUTION - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def conv2d(image, kernel, stride=1, padding=0):\n",
                "    \"\"\"\n",
                "    2D Convolution operation (NumPy only).\n",
                "    \n",
                "    Args:\n",
                "        image: Input image (H, W) or (H, W, C)\n",
                "        kernel: Convolution kernel (k_h, k_w)\n",
                "        stride: Step size for sliding window\n",
                "        padding: Zero-padding around image\n",
                "    \n",
                "    Returns:\n",
                "        Convolved output\n",
                "    \"\"\"\n",
                "    # Handle grayscale vs RGB\n",
                "    if len(image.shape) == 2:\n",
                "        image = image[:, :, np.newaxis]\n",
                "    \n",
                "    H, W, C = image.shape\n",
                "    k_h, k_w = kernel.shape\n",
                "    \n",
                "    # Apply padding\n",
                "    if padding > 0:\n",
                "        image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
                "        H, W, C = image.shape\n",
                "    \n",
                "    # Calculate output dimensions\n",
                "    out_h = (H - k_h) // stride + 1\n",
                "    out_w = (W - k_w) // stride + 1\n",
                "    \n",
                "    # Initialize output\n",
                "    output = np.zeros((out_h, out_w, C))\n",
                "    \n",
                "    # Perform convolution\n",
                "    for c in range(C):\n",
                "        for i in range(out_h):\n",
                "            for j in range(out_w):\n",
                "                # Extract region\n",
                "                region = image[i*stride:i*stride+k_h, j*stride:j*stride+k_w, c]\n",
                "                # Element-wise multiply and sum\n",
                "                output[i, j, c] = np.sum(region * kernel)\n",
                "    \n",
                "    return output.squeeze()  # Remove channel dim if grayscale\n",
                "\n",
                "print(\"‚úÖ conv2d() function defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# COMMON KERNELS\n",
                "# ============================================================\n",
                "\n",
                "# Edge Detection Kernels\n",
                "SOBEL_X = np.array([[-1, 0, 1],\n",
                "                    [-2, 0, 2],\n",
                "                    [-1, 0, 1]], dtype=np.float32)\n",
                "\n",
                "SOBEL_Y = np.array([[-1, -2, -1],\n",
                "                    [ 0,  0,  0],\n",
                "                    [ 1,  2,  1]], dtype=np.float32)\n",
                "\n",
                "LAPLACIAN = np.array([[ 0, -1,  0],\n",
                "                      [-1,  4, -1],\n",
                "                      [ 0, -1,  0]], dtype=np.float32)\n",
                "\n",
                "# Blur Kernels\n",
                "BOX_BLUR = np.ones((3, 3), dtype=np.float32) / 9\n",
                "\n",
                "GAUSSIAN_3x3 = np.array([[1, 2, 1],\n",
                "                         [2, 4, 2],\n",
                "                         [1, 2, 1]], dtype=np.float32) / 16\n",
                "\n",
                "# Sharpen Kernel\n",
                "SHARPEN = np.array([[ 0, -1,  0],\n",
                "                    [-1,  5, -1],\n",
                "                    [ 0, -1,  0]], dtype=np.float32)\n",
                "\n",
                "print(\"‚úÖ Kernels defined\")\n",
                "print(f\"\\nSobel X (vertical edges):\\n{SOBEL_X}\")\n",
                "print(f\"\\nGaussian Blur:\\n{GAUSSIAN_3x3}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize convolution effects\n",
                "def visualize_convolutions(image_path):\n",
                "    \"\"\"Apply different kernels and visualize results.\"\"\"\n",
                "    \n",
                "    img = np.array(Image.open(image_path).convert('L'))  # Grayscale\n",
                "    \n",
                "    kernels = [\n",
                "        ('Original', None),\n",
                "        ('Sobel X (Vertical Edges)', SOBEL_X),\n",
                "        ('Sobel Y (Horizontal Edges)', SOBEL_Y),\n",
                "        ('Laplacian (All Edges)', LAPLACIAN),\n",
                "        ('Box Blur', BOX_BLUR),\n",
                "        ('Sharpen', SHARPEN)\n",
                "    ]\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "    fig.suptitle('üî¨ Convolution Effects (NumPy Implementation)', fontsize=14, fontweight='bold')\n",
                "    \n",
                "    for ax, (name, kernel) in zip(axes.flat, kernels):\n",
                "        if kernel is None:\n",
                "            result = img\n",
                "        else:\n",
                "            result = conv2d(img.astype(np.float32), kernel, padding=1)\n",
                "        \n",
                "        ax.imshow(result, cmap='gray')\n",
                "        ax.set_title(name)\n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'convolution_effects.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "# Find sample image\n",
                "sample_dir = PROJECT_ROOT / \"data\" / \"processed\" / \"images\" / \"train\"\n",
                "samples = list(sample_dir.glob(\"*.jpg\"))[:1]\n",
                "if samples:\n",
                "    visualize_convolutions(samples[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: Activation Functions\n",
                "\n",
                "## üìê Why Non-Linearity?\n",
                "\n",
                "Without activation functions, a neural network is just a linear transformation:\n",
                "$$\n",
                "y = W_n \\cdot (W_{n-1} \\cdot ... \\cdot (W_1 \\cdot x)) = W_{combined} \\cdot x\n",
                "$$\n",
                "\n",
                "Activation functions introduce **non-linearity**, enabling networks to learn complex patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# ACTIVATION FUNCTIONS - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def sigmoid(x):\n",
                "    \"\"\"Sigmoid: œÉ(x) = 1 / (1 + e^(-x))\"\"\"\n",
                "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
                "\n",
                "def sigmoid_derivative(x):\n",
                "    \"\"\"dœÉ/dx = œÉ(x) √ó (1 - œÉ(x))\"\"\"\n",
                "    s = sigmoid(x)\n",
                "    return s * (1 - s)\n",
                "\n",
                "def tanh(x):\n",
                "    \"\"\"tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))\"\"\"\n",
                "    return np.tanh(x)\n",
                "\n",
                "def tanh_derivative(x):\n",
                "    \"\"\"d(tanh)/dx = 1 - tanh¬≤(x)\"\"\"\n",
                "    return 1 - np.tanh(x)**2\n",
                "\n",
                "def relu(x):\n",
                "    \"\"\"ReLU: max(0, x)\"\"\"\n",
                "    return np.maximum(0, x)\n",
                "\n",
                "def relu_derivative(x):\n",
                "    \"\"\"dReLU/dx = 1 if x > 0 else 0\"\"\"\n",
                "    return (x > 0).astype(np.float32)\n",
                "\n",
                "def leaky_relu(x, alpha=0.01):\n",
                "    \"\"\"Leaky ReLU: max(Œ±x, x)\"\"\"\n",
                "    return np.where(x > 0, x, alpha * x)\n",
                "\n",
                "def silu(x):\n",
                "    \"\"\"SiLU/Swish (used in YOLOv11): x √ó œÉ(x)\"\"\"\n",
                "    return x * sigmoid(x)\n",
                "\n",
                "def silu_derivative(x):\n",
                "    \"\"\"d(SiLU)/dx = œÉ(x) + x √ó œÉ(x) √ó (1 - œÉ(x))\"\"\"\n",
                "    s = sigmoid(x)\n",
                "    return s + x * s * (1 - s)\n",
                "\n",
                "def softmax(x):\n",
                "    \"\"\"Softmax: exp(x_i) / Œ£exp(x_j)\"\"\"\n",
                "    exp_x = np.exp(x - np.max(x))  # Numerical stability\n",
                "    return exp_x / np.sum(exp_x)\n",
                "\n",
                "print(\"‚úÖ Activation functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize activation functions\n",
                "x = np.linspace(-5, 5, 200)\n",
                "\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
                "fig.suptitle('üìà Activation Functions (NumPy Implementation)', fontsize=14, fontweight='bold')\n",
                "\n",
                "activations = [\n",
                "    ('Sigmoid', sigmoid, sigmoid_derivative),\n",
                "    ('Tanh', tanh, tanh_derivative),\n",
                "    ('ReLU', relu, relu_derivative),\n",
                "    ('Leaky ReLU', leaky_relu, lambda x: np.where(x > 0, 1, 0.01)),\n",
                "    ('SiLU/Swish (YOLOv11)', silu, silu_derivative),\n",
                "    ('Softmax Output', lambda x: np.array([softmax(np.array([xi, 0, -xi])) for xi in x]), None)\n",
                "]\n",
                "\n",
                "for ax, (name, func, deriv) in zip(axes.flat, activations):\n",
                "    if 'Softmax' not in name:\n",
                "        ax.plot(x, func(x), 'b-', linewidth=2, label='f(x)')\n",
                "        if deriv:\n",
                "            ax.plot(x, deriv(x), 'r--', linewidth=1.5, label=\"f'(x)\")\n",
                "        ax.axhline(y=0, color='k', linewidth=0.5)\n",
                "        ax.axvline(x=0, color='k', linewidth=0.5)\n",
                "        ax.legend()\n",
                "    else:\n",
                "        y = func(x)\n",
                "        ax.plot(x, y[:, 0], label='Class 0')\n",
                "        ax.plot(x, y[:, 1], label='Class 1')\n",
                "        ax.plot(x, y[:, 2], label='Class 2')\n",
                "        ax.legend()\n",
                "    ax.set_title(name)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'activation_functions.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 3: Pooling Operations\n",
                "\n",
                "## üìê Mathematical Definition\n",
                "\n",
                "**Max Pooling:**\n",
                "$$\n",
                "y[i,j] = \\max_{(m,n) \\in R_{ij}} x[m,n]\n",
                "$$\n",
                "\n",
                "**Average Pooling:**\n",
                "$$\n",
                "y[i,j] = \\frac{1}{|R|} \\sum_{(m,n) \\in R_{ij}} x[m,n]\n",
                "$$\n",
                "\n",
                "Where R is the pooling region."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# POOLING OPERATIONS - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def max_pool2d(image, pool_size=2, stride=2):\n",
                "    \"\"\"2D Max Pooling.\"\"\"\n",
                "    if len(image.shape) == 2:\n",
                "        image = image[:, :, np.newaxis]\n",
                "    \n",
                "    H, W, C = image.shape\n",
                "    out_h = (H - pool_size) // stride + 1\n",
                "    out_w = (W - pool_size) // stride + 1\n",
                "    \n",
                "    output = np.zeros((out_h, out_w, C))\n",
                "    \n",
                "    for c in range(C):\n",
                "        for i in range(out_h):\n",
                "            for j in range(out_w):\n",
                "                region = image[i*stride:i*stride+pool_size, \n",
                "                              j*stride:j*stride+pool_size, c]\n",
                "                output[i, j, c] = np.max(region)\n",
                "    \n",
                "    return output.squeeze()\n",
                "\n",
                "def avg_pool2d(image, pool_size=2, stride=2):\n",
                "    \"\"\"2D Average Pooling.\"\"\"\n",
                "    if len(image.shape) == 2:\n",
                "        image = image[:, :, np.newaxis]\n",
                "    \n",
                "    H, W, C = image.shape\n",
                "    out_h = (H - pool_size) // stride + 1\n",
                "    out_w = (W - pool_size) // stride + 1\n",
                "    \n",
                "    output = np.zeros((out_h, out_w, C))\n",
                "    \n",
                "    for c in range(C):\n",
                "        for i in range(out_h):\n",
                "            for j in range(out_w):\n",
                "                region = image[i*stride:i*stride+pool_size,\n",
                "                              j*stride:j*stride+pool_size, c]\n",
                "                output[i, j, c] = np.mean(region)\n",
                "    \n",
                "    return output.squeeze()\n",
                "\n",
                "print(\"‚úÖ Pooling functions defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize pooling\n",
                "def visualize_pooling(image_path):\n",
                "    \"\"\"Show pooling effects.\"\"\"\n",
                "    img = np.array(Image.open(image_path).convert('L').resize((128, 128)))\n",
                "    \n",
                "    max_pooled = max_pool2d(img.astype(np.float32))\n",
                "    avg_pooled = avg_pool2d(img.astype(np.float32))\n",
                "    \n",
                "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
                "    fig.suptitle('üî≤ Pooling Operations (2√ó2, stride=2)', fontsize=14, fontweight='bold')\n",
                "    \n",
                "    axes[0].imshow(img, cmap='gray')\n",
                "    axes[0].set_title(f'Original ({img.shape[0]}√ó{img.shape[1]})')\n",
                "    \n",
                "    axes[1].imshow(max_pooled, cmap='gray')\n",
                "    axes[1].set_title(f'Max Pool ({max_pooled.shape[0]}√ó{max_pooled.shape[1]})')\n",
                "    \n",
                "    axes[2].imshow(avg_pooled, cmap='gray')\n",
                "    axes[2].set_title(f'Avg Pool ({avg_pooled.shape[0]}√ó{avg_pooled.shape[1]})')\n",
                "    \n",
                "    for ax in axes:\n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(PROJECT_ROOT / 'docs' / 'assets' / 'pooling_demo.png', dpi=150)\n",
                "    plt.show()\n",
                "\n",
                "if samples:\n",
                "    visualize_pooling(samples[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 4: Batch Normalization\n",
                "\n",
                "## üìê Mathematical Definition\n",
                "\n",
                "$$\n",
                "\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
                "$$\n",
                "$$\n",
                "y_i = \\gamma \\hat{x}_i + \\beta\n",
                "$$\n",
                "\n",
                "Where:\n",
                "- Œº_B = batch mean\n",
                "- œÉ¬≤_B = batch variance\n",
                "- Œ≥, Œ≤ = learnable parameters\n",
                "- Œµ = small constant for stability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# BATCH NORMALIZATION - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "def batch_norm(x, gamma=1.0, beta=0.0, epsilon=1e-5):\n",
                "    \"\"\"\n",
                "    Batch Normalization (NumPy).\n",
                "    \n",
                "    Args:\n",
                "        x: Input array (N, ...) - first dim is batch\n",
                "        gamma: Scale parameter\n",
                "        beta: Shift parameter\n",
                "        epsilon: Numerical stability\n",
                "    \"\"\"\n",
                "    # Compute batch statistics\n",
                "    mu = np.mean(x, axis=0)\n",
                "    var = np.var(x, axis=0)\n",
                "    \n",
                "    # Normalize\n",
                "    x_norm = (x - mu) / np.sqrt(var + epsilon)\n",
                "    \n",
                "    # Scale and shift\n",
                "    out = gamma * x_norm + beta\n",
                "    \n",
                "    return out, mu, var\n",
                "\n",
                "# Test\n",
                "test_batch = np.random.randn(32, 64, 64)  # Batch of 32, 64x64\n",
                "normalized, mu, var = batch_norm(test_batch)\n",
                "\n",
                "print(f\"‚úÖ BatchNorm test:\")\n",
                "print(f\"   Input mean: {test_batch.mean():.4f}, std: {test_batch.std():.4f}\")\n",
                "print(f\"   Output mean: {normalized.mean():.4f}, std: {normalized.std():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 5: Simple Forward Pass\n",
                "\n",
                "Let's combine everything into a simple CNN layer!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# SIMPLE CNN LAYER - NumPy Implementation\n",
                "# ============================================================\n",
                "\n",
                "class ConvLayer:\n",
                "    \"\"\"Basic Convolutional Layer (NumPy only).\"\"\"\n",
                "    \n",
                "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
                "        self.stride = stride\n",
                "        self.padding = padding\n",
                "        \n",
                "        # Initialize weights (He initialization)\n",
                "        scale = np.sqrt(2.0 / (in_channels * kernel_size * kernel_size))\n",
                "        self.weights = np.random.randn(out_channels, in_channels, kernel_size, kernel_size) * scale\n",
                "        self.bias = np.zeros(out_channels)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        \"\"\"Forward pass.\"\"\"\n",
                "        # x shape: (C, H, W)\n",
                "        C, H, W = x.shape\n",
                "        out_channels = self.weights.shape[0]\n",
                "        k = self.weights.shape[2]\n",
                "        \n",
                "        # Pad\n",
                "        if self.padding > 0:\n",
                "            x = np.pad(x, ((0, 0), (self.padding, self.padding), (self.padding, self.padding)))\n",
                "        \n",
                "        _, H_pad, W_pad = x.shape\n",
                "        out_h = (H_pad - k) // self.stride + 1\n",
                "        out_w = (W_pad - k) // self.stride + 1\n",
                "        \n",
                "        output = np.zeros((out_channels, out_h, out_w))\n",
                "        \n",
                "        for oc in range(out_channels):\n",
                "            for i in range(out_h):\n",
                "                for j in range(out_w):\n",
                "                    region = x[:, i*self.stride:i*self.stride+k, j*self.stride:j*self.stride+k]\n",
                "                    output[oc, i, j] = np.sum(region * self.weights[oc]) + self.bias[oc]\n",
                "        \n",
                "        return output\n",
                "\n",
                "# Test\n",
                "conv = ConvLayer(3, 16, kernel_size=3)\n",
                "test_input = np.random.randn(3, 64, 64)  # RGB 64x64\n",
                "output = conv.forward(test_input)\n",
                "output = relu(output)  # Apply activation\n",
                "output = max_pool2d(output.transpose(1, 2, 0)).transpose(2, 0, 1)  # Pool\n",
                "\n",
                "print(f\"‚úÖ Conv Layer Test:\")\n",
                "print(f\"   Input shape: {test_input.shape}\")\n",
                "print(f\"   Output shape (after pool): {output.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù Summary\n",
                "\n",
                "### Implemented from Scratch (NumPy only):\n",
                "\n",
                "| Component | Formula | Function |\n",
                "|-----------|---------|----------|\n",
                "| **Convolution** | Œ£ I[i+m,j+n] √ó K[m,n] | `conv2d()` |\n",
                "| **ReLU** | max(0, x) | `relu()` |\n",
                "| **Sigmoid** | 1/(1+e^-x) | `sigmoid()` |\n",
                "| **SiLU** | x √ó œÉ(x) | `silu()` |\n",
                "| **Max Pool** | max(region) | `max_pool2d()` |\n",
                "| **Avg Pool** | mean(region) | `avg_pool2d()` |\n",
                "| **BatchNorm** | (x-Œº)/‚àö(œÉ¬≤+Œµ) | `batch_norm()` |\n",
                "\n",
                "### Next: Task 6 - Object Detection Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ TASK 5 COMPLETE: CNN Fundamentals with NumPy\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüìã Implemented (NumPy only, no PyTorch!):\")\n",
                "print(\"   ‚úì 2D Convolution operation\")\n",
                "print(\"   ‚úì Edge detection kernels (Sobel, Laplacian)\")\n",
                "print(\"   ‚úì Activation functions (ReLU, Sigmoid, Tanh, SiLU)\")\n",
                "print(\"   ‚úì Pooling operations (Max, Average)\")\n",
                "print(\"   ‚úì Batch Normalization\")\n",
                "print(\"   ‚úì Simple ConvLayer class\")\n",
                "print(\"\\n‚û°Ô∏è Ready for Task 6: Object Detection Metrics\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}